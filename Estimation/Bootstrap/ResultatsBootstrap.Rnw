\documentclass[11pt,oneside, a4paper]{amsart}
\usepackage{natbib}

\usepackage{amsbsy,amsmath}
\usepackage{amssymb,amsfonts}
\usepackage{bbm}%give 1 with dbl vertical bar 
\usepackage{booktabs,url,enumerate}
\usepackage{color,xcolor,colortbl}
\usepackage{float}
\usepackage{tikz}
\usepackage{rotating,graphicx,lscape}
\usepackage{commath}
\usetikzlibrary{arrows,positioning} 
\usepackage[hypcap]{caption}
\newcommand{\sgn}{\mathrm{sign}}
\usepackage{setspace}

% bold rows
\usepackage{array}
\newcolumntype{$}{>{\global\let\currentrowstyle\relax}}
\newcolumntype{^}{>{\currentrowstyle}}
\newcommand{\rowstyle}[1]{\gdef\currentrowstyle{#1}%
  #1\ignorespaces
}

% Invisible table columns!
\newcolumntype{H}{>{\setbox0=\hbox\bgroup}c<{\egroup}@{}}% Properly placed sideways table with asmart class. 

\setlength\rotFPtop{0pt plus 1fil} 


\usepackage[top=1.5cm, bottom=1.5cm, left=3.0cm, right=3.0cm]{geometry}

\DeclareMathOperator{\Med}{\mathbb{M}ed}
\DeclareMathOperator{\Mean}{\mathbb{M}ean}
\DeclareMathOperator{\Cov}{\mathbb{C}ov}
\DeclareMathOperator{\Var}{\mathbb{V}ar}
\DeclareMathOperator{\E}{\mathbb{E}}
\DeclareMathOperator{\nid}{NID}
\DeclareMathOperator{\N}{\mathcal{N}}
\DeclareMathOperator{\corr}{corr}
\DeclareMathOperator{\diag}{diag}
\onehalfspace


\definecolor{LightRed}{rgb}{1,.88,.88}
\definecolor{LightBlue}{rgb}{.88,.88,1}
\definecolor{LightGreen}{rgb}{.88,1,.88}

\newtheorem{theorem}{Theorem}
\begin{document}

  
\title{Bootstrap Results}   
\author{ClÃ©ment Carrier}
\date{\today}
\maketitle


\section*{Bootstrap}


<<message=FALSE>>=
library(knitr)
library(glmnet) 
library(MASS)
library(xtable) 
require(ggplot2)
@


<<my-chunk-label>>=

@

<<>>=
source('../../laurent/lasso.R')
source('../../Functions/RW.R')
source('../../Functions/fun.R')
source('../../Functions/lahiri.R')
source('../../Functions/lahiriboot.R')
@


We simulate the data by choosing, the sparsity of the true parameter (4 non zero coefficient in this case), the number of covariates, the number of observations and the nature of the noise (here we choose iid N(0,1)). 

<<echo=FALSE>>=
p=10
n=100
nonzero=4

norm<-NULL
for (i in 1:p){
  norm<-cbind(norm,as.matrix(rnorm(n,0,1),n,1))
}
beta<-matrix(c(3,3,-1,-1,rep(0,p-nonzero)))

y<-norm%*%beta+matrix(rnorm(n,0,1),n,1)
df<-data.frame(y,norm)
@

<<echo=FALSE>>=
a<-lahiriboot(df,10,0.05,nonzero)
@

<<echo=FALSE>>=
p=60
n=100
nonzero=4
norm<-NULL
for (i in 1:p){
  norm<-cbind(norm,as.matrix(rnorm(n,0,1),n,1))
}
beta<-matrix(c(3,3,-1,-1,rep(0,p-nonzero)))
y<-norm%*%beta+matrix(rnorm(n,0,1),n,1)
df<-data.frame(y,norm)
b<-lahiriboot(df,10,0.05,nonzero)
@

<<echo=FALSE>>=
p=150
n=100
nonzero=4
norm<-NULL
for (i in 1:p){
  norm<-cbind(norm,as.matrix(rnorm(n,0,1),n,1))
}
beta<-matrix(c(3,3,-1,-1,rep(0,p-nonzero)))
y<-norm%*%beta+matrix(rnorm(n,0,1),n,1)
df<-data.frame(y,norm)
c<-lahiriboot(df,10,0.05,nonzero)
@

<<>>=
cov<-matrix(c(a[2],b[2],c[2]))
size<-matrix(c(a[1],b[1],c[1]))

@



<< results='asis', echo=FALSE>>=
dataframe <- data.frame(Model = 1:3,
                  pn = c("(10,100)", "(60,100)", "(150,100)"),
                  cove = cov ,
                  leng = size  )
                 

print(xtable(dataframe, digits=3, caption="Simulation Result", label="Test_table"), 
      size="footnotesize", #Change size; useful for bigger tables
      include.rownames=FALSE, #Don't print rownames
      include.colnames=FALSE, #We create them ourselves
      caption.placement="top", 
      hline.after=NULL, #We don't need hline; we use booktabs
      add.to.row = list(pos = list(-1,nrow(dataframe)),
                        command = c(paste("\\toprule \n",
                         "Model & (p,n) & coverage & lenght \\\\\n", 
                          "\\midrule \n"),"\\bottomrule \n")
                        )
      )
@


Then we compute the method used by lahiri (On the residual empirical process based on the ALASSO in high dimensions and its functional oracle property). In this paper, Lahiri uses the ALASSO estimator and shows that the empirical distribution of estimated residual behaves like the distribution of the gaussian noise. He then deduces a confidence band of prediction of the variable of interest (y) based on the empirical distribution of the residual.

<<echo=FALSE>>=
CI<-function(p,n,iter,nonzero){
  beta<-matrix(c(3,3,-1,-1,rep(0,p-nonzero)))
  size<-rep(0,iter)
  cov<-rep(0,iter)
  for (j in 1:iter){
    norm<- matrix(rnorm(n*p,0,1),n,p)
    y<-norm%*%beta+matrix(rnorm(n,0,1),n,1)
    df<-data.frame(y,norm)
    size[j]<-lahiri(df,0.05)[1]
    cov[j]<-lahiri(df,0.05)[2]
  }
  v1<-mean(size)
  v2<-mean(cov)
  return(c(v1,v2))
}
x<-CI(10,100,10,4)
w<-CI(60,100,10,4)
z<-CI(150,100,10,4)
@


<<>>=
co<-matrix(c(x[2],w[2],z[2]))
siz<-matrix(c(x[1],w[1],z[1]))
@



<< results='asis', echo=FALSE>>=
dataframe <- data.frame(Model = 1:3,
                  pn = c("(10,100)", "(60,100)", "(150,100)"),
                  cove = co ,
                  leng = siz  )
                 

print(xtable(dataframe, digits=3, caption="Simulation Result", label="Test_table"), 
      size="footnotesize", #Change size; useful for bigger tables
      include.rownames=FALSE, #Don't print rownames
      include.colnames=FALSE, #We create them ourselves
      caption.placement="top", 
      hline.after=NULL, #We don't need hline; we use booktabs
      add.to.row = list(pos = list(-1,nrow(dataframe)),
                        command = c(paste("\\toprule \n",
                         "Model & (p,n) & coverage & lenght \\\\\n", 
                          "\\midrule \n"),"\\bottomrule \n")
                        )
      )
@




\end{document}